{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu-ibanks-3.hep.caltech.edu  Tue Aug 24 14:28:59 2021  470.57.02\n",
      "[0] NVIDIA GeForce GTX 1080 | 24'C,   0 % |     1 /  8119 MB |\n",
      "[1] NVIDIA GeForce GTX 1080 | 26'C,   0 % |     1 /  8119 MB |\n",
      "[2] NVIDIA GeForce GTX 1080 | 27'C,   0 % |     1 /  8119 MB |\n",
      "[3] NVIDIA GeForce GTX 1080 | 24'C,   0 % |     1 /  8119 MB |\n",
      "[4] NVIDIA GeForce GTX 1080 | 27'C,   0 % |     1 /  8119 MB |\n",
      "[5] NVIDIA GeForce GTX 1080 | 27'C,   0 % |   727 /  8119 MB | 3012(723M)\n",
      "[6] NVIDIA GeForce GTX 1080 | 27'C,   0 % |     1 /  8119 MB |\n",
      "[7] NVIDIA GeForce GTX 1080 | 28'C,   0 % |     1 /  8119 MB |\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "import ROOT as rt\n",
    "import uproot\n",
    "#from root_numpy import root2array, tree2array\n",
    "#from root_pandas import read_root\n",
    "import h5py \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as nlr\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "try:\n",
    "    import setGPU\n",
    "except:\n",
    "    os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "\n",
    "import gpustat\n",
    "gpustat.print_gpustat()\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samp_to_df(samp_name, total_num):\n",
    "    dfs = []\n",
    "    tree_vars = [b'leading_photon_pt', b'subleading_photon_pt', b'diphoton_pt', b'diphoton_mass',\n",
    "           b'leading_bjet_pt', b'subleading_bjet_pt', b'dibjet_pt', b'dibjet_mass',\n",
    "           b'leading_bjet_pt_corr', b'subleading_bjet_pt_corr', b'dibjet_pt_corr', b'dibjet_mass_corr',\n",
    "           b'leading_pho_pt_over_dimass', b'leading_bjet_pt_over_dimass', b'leading_bjet_pt_over_dimass_corr',\n",
    "           b'subleading_pho_pt_over_dimass', b'subleading_bjet_pt_over_dimass', b'subleading_bjet_pt_over_dimass_corr',\n",
    "           b'leading_photon_phi', b'leading_photon_eta', b'subleading_photon_phi', b'subleading_photon_eta',\n",
    "           b'diphoton_eta', b'photon_delR', b'diphoton_pt_over_diphoton_mass',\n",
    "           b'leading_bjet_phi', b'leading_bjet_eta', b'subleading_bjet_phi', b'subleading_bjet_eta',\n",
    "           b'dibjet_eta', b'bjet_delR', b'dibjet_pt_over_dibjet_mass', b'dibjet_pt_over_dibjet_mass_corr',\n",
    "           b'leadingDeepBscore', b'subleadingDeepBscore', b'sumDeepBscore',\n",
    "           b'rec_pho_bjet_min_dR', b'all_pho_bjet_min_dR', b'dphi_met_leading_bjet', b'dphi_met_subleading_bjet',\n",
    "           b'leading_vbfjet_pt', b'subleading_vbfjet_pt', b'divbfjet_pt', b'divbfjet_mass',\n",
    "           b'leading_vbfjet_phi', b'leading_vbfjet_eta', b'subleading_vbfjet_phi', b'subleading_vbfjet_eta',\n",
    "           b'leading_vbfjet_pt_over_dimass', b'subleading_vbfjet_pt_over_dimass', b'divbfjet_pt_over_dimass',\n",
    "           b'divbfjet_eta', b'vbfjet_delR', b'vbfjet_del_eta',\n",
    "           b'MET_pt', b'MET_phi', b'MET_sumEt',\n",
    "           b'recon', b'ggHH_recon', b'VBFHH_recon', b'genweight', b'nbjet', b'nvbfjet', b'nphoton', b'njet',\n",
    "           b'run', b'lumi', b'event']\n",
    "    for i in range(total_num+1):\n",
    "        file_name = f'/storage/af/user/schen7/CMSSW_9_4_2/src/Higgs/HHbbgg/HHbbggAna/condor/output/{samp_name}{i}.root'\n",
    "        samp_file = uproot.open(file_name)\n",
    "        samp_array = samp_file['tree'].arrays(tree_vars)\n",
    "        samp_df = pd.DataFrame(samp_array)\n",
    "        dfs.append(samp_df)\n",
    "    combine_df = pd.concat(dfs)\n",
    "    return combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframes - 2018 \n",
    "\n",
    "# Signals\n",
    "GluGluToHH_df_2018 = samp_to_df('job_2_ntuple20180819v1/GluGluToHHTo2B2G_node_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8Job2ifile', 0)\n",
    "VBFHH_df_2018= samp_to_df('job_3_ntuple20180819v1/VBFHHTo2B2G_CV_1_C2V_1_C3_1_TuneCP5_PSWeights_13TeV-madgraph-pythia8Job3ifile', 0)\n",
    "\n",
    "# Backgrounds\n",
    "VHToGG_df_2018 = samp_to_df('job_4_ntuple20180819v1/VHToGG_M125_13TeV_amcatnloFXFX_madspin_pythia8Job4ifile', 0)\n",
    "ttHToGG_df_2018 = samp_to_df('job_5_ntuple20180819v1/ttHToGG_M125_TuneCP5_PSweights_13TeV-powheg-pythia8Job5ifile', 0)\n",
    "VBFHToGG_df_2018 = samp_to_df('job_6_ntuple20180819v1/VBFHToGG_M125_13TeV_amcatnlo_pythia8Job6ifile', 0)\n",
    "GluGluHToGG_df_2018 = samp_to_df('job_7_ntuple20180819v1/GluGluHToGG_M125_TuneCP5_13TeV-amcatnloFXFX-pythia8Job7ifile', 0)\n",
    "TTJets_df_2018 = samp_to_df('job_8_ntuple20180819v1/TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8Job8ifile', 60)\n",
    "TTGJets_df_2018 = samp_to_df('job_9_ntuple20180819v1/TTGJets_TuneCP5_13TeV-amcatnloFXFX-madspin-pythia8Job9ifile', 3)\n",
    "TTGG_0Jets_df_2018 = samp_to_df('job_10_ntuple20180819v1/TTGG_0Jets_TuneCP5_13TeV_amcatnlo_madspin_pythia8Job10ifile', 5)\n",
    "GJet_SmallPt_df_2018 = samp_to_df('job_11_ntuple20180819v1/GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job11ifile', 3)\n",
    "GJet_BigPt_df_2018 = samp_to_df('job_12_ntuple20180819v1/GJet_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job12ifile', 2)\n",
    "DiPhotonJetsBox_df_2018 = samp_to_df('job_13_ntuple20180819v1/DiPhotonJetsBox_MGG-80toInf_13TeV-SherpaJob13ifile', 4)\n",
    "DiPhotonJetsBox1B_df_2018 = samp_to_df('job_14_ntuple20180819v1/DiPhotonJetsBox1BJet_MGG-80toInf_13TeV-SherpaJob14ifile', 0)\n",
    "DiPhotonJetsBox2B_df_2018 = samp_to_df('job_15_ntuple20180819v1/DiPhotonJetsBox2BJets_MGG-80toInf_13TeV-SherpaJob15ifile', 0)\n",
    "QCD_Jets_df_2018 = samp_to_df('job_16_ntuple20180819v1/QCD_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job16ifile', 15)\n",
    "\n",
    "# Set up dataframes - 2017\n",
    "\n",
    "# Signals\n",
    "GluGluToHH_df_2017 = samp_to_df('job_2_ntuple20170819v1/GluGluToHHTo2B2G_node_cHHH1_TuneCP5_PSWeights_13TeV-powheg-pythia8Job2ifile', 3)\n",
    "VBFHH_df_2017 = samp_to_df('job_3_ntuple20170819v1/VBFHHTo2B2G_CV_1_C2V_1_C3_1_13TeV-madgraphJob3ifile', 1)\n",
    "\n",
    "# Backgrounds\n",
    "VHToGG_df_2017 = samp_to_df('job_4_ntuple20170819v1/VHToGG_M125_13TeV_amcatnloFXFX_madspin_pythia8Job4ifile', 0)\n",
    "ttHToGG_df_2017 = samp_to_df('job_5_ntuple20170819v1/ttHToGG_M125_13TeV_powheg_pythia8Job5ifile', 0)\n",
    "VBFHToGG_df_2017 = samp_to_df('job_6_ntuple20170819v1/VBFHToGG_M-125_13TeV_powheg_pythia8Job6ifile', 2)\n",
    "GluGluHToGG_df_2017 = samp_to_df('job_7_ntuple20170819v1/GluGluHToGG_M-125_13TeV_powheg_pythia8Job7ifile', 0)\n",
    "TTJets_df_2017 = samp_to_df('job_8_ntuple20170819v1/TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8Job8ifile', 38)\n",
    "TTGJets_df_2017 = samp_to_df('job_9_ntuple20170819v1/TTGJets_TuneCP5_13TeV-amcatnloFXFX-madspin-pythia8Job9ifile', 10)\n",
    "TTGG_0Jets_df_2017 = samp_to_df('job_10_ntuple20170819v1/TTGG_0Jets_TuneCP5_13TeV_amcatnlo_madspin_pythia8Job10ifile', 1)\n",
    "GJet_SmallPt_df_2017 = samp_to_df('job_11_ntuple20170819v1/GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job11ifile', 2)\n",
    "GJet_BigPt_df_2017 = samp_to_df('job_12_ntuple20170819v1/GJet_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job12ifile', 20)\n",
    "DiPhotonJetsBox_df_2017 = samp_to_df('job_1_ntuple20170819v2/DiPhotonJetsBox_MGG-80toInf_13TeV-SherpaJob1ifile', 16)\n",
    "DiPhotonJetsBox1B_df_2017 = samp_to_df('job_14_ntuple20170819v1/DiPhotonJetsBox1BJet_MGG-80toInf_13TeV-SherpaJob14ifile', 3)\n",
    "DiPhotonJetsBox2B_df_2017 = samp_to_df('job_15_ntuple20170819v1/DiPhotonJetsBox2BJets_MGG-80toInf_13TeV-SherpaJob15ifile', 5)\n",
    "QCD_Jets_df_2017 = samp_to_df('job_16_ntuple20170819v1/QCD_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCP5_13TeV_Pythia8Job16ifile', 3)\n",
    "\n",
    "# Set up dataframes - 2016 \n",
    "\n",
    "# Signals\n",
    "GluGluToHH_df_2016 = samp_to_df('job_2_ntuple20160819v1/GluGluToHHTo2B2G_node_cHHH1_TuneCUETP8M1_PSWeights_13TeV-powheg-pythia8Job2ifile', 0)\n",
    "VBFHH_df_2016 = samp_to_df('job_3_ntuple20160819v1/VBFHHTo2B2G_CV_1_C2V_1_C3_1_13TeV-madgraphJob3ifile', 0)\n",
    "\n",
    "# Background\n",
    "VHToGG_df_2016 = samp_to_df('job_4_ntuple20160819v1/VHToGG_M125_13TeV_amcatnloFXFX_madspin_pythia8Job4ifile', 0)\n",
    "ttHToGG_df_2016 = samp_to_df('job_5_ntuple20160819v1/ttHToGG_M125_13TeV_powheg_pythia8_v2Job5ifile', 0)\n",
    "VBFHToGG_df_2016 = samp_to_df('job_6_ntuple20160819v1/VBFHToGG_M125_13TeV_amcatnlo_pythia8_v2Job6ifile', 2)\n",
    "GluGluHToGG_df_2016 = samp_to_df('job_7_ntuple20160819v1/GluGluHToGG_M125_13TeV_amcatnloFXFX_pythiaJob7ifile', 0)\n",
    "TTJets_df_2016 = samp_to_df('job_8_ntuple20160819v1/TTJets_TuneCUETP8M2T4_13TeV-amcatnloFXFX-pythia8Job8ifile', 8)\n",
    "TTGJets_df_2016 = samp_to_df('job_9_ntuple20160819v1/TTGJets_TuneCUETP8M1_13TeV-amcatnloFXFX-madspin-pythia8Job9ifile', 2)\n",
    "TTGG_0Jets_df_2016 = samp_to_df('job_10_ntuple20160819v1/TTGG_0Jets_TuneCUETP8M1_13TeV_amcatnlo_madspin_pythia8Job10ifile', 0)\n",
    "GJet_SmallPt_df_2016 = samp_to_df('job_11_ntuple20160819v1/GJet_Pt-20to40_DoubleEMEnriched_MGG-80toInf_TuneCUETP8M1_13TeV_Pythia8Job11ifile', 2)\n",
    "GJet_BigPt_df_2016 = samp_to_df('job_12_ntuple20160819v1/GJet_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCUETP8M1_13TeV_Pythia8Job12ifile', 12)\n",
    "DiPhotonJetsBox_df_2016 = samp_to_df('job_13_ntuple20160819v1/DiPhotonJetsBox_MGG-80toInf_13TeV-SherpaJob13ifile', 9)\n",
    "DiPhotonJetsBox1B_df_2016 = samp_to_df('job_14_ntuple20160819v1/DiPhotonJetsBox1BJet_MGG-80toInf_TuneSherpa_13TeV-SherpaJob14ifile', 3)\n",
    "DiPhotonJetsBox2B_df_2016 = samp_to_df('job_15_ntuple20160819v1/DiPhotonJetsBox2BJets_MGG-80toInf_TuneSherpa_13TeV-SherpaJob15ifile', 4)\n",
    "QCD_Jets_df_2016 = samp_to_df('job_16_ntuple20160819v1/QCD_Pt-40toInf_DoubleEMEnriched_MGG-80toInf_TuneCUETP8M1_13TeV_Pythia8Job16ifile', 3)\n",
    "\n",
    "# Combine by sample (recon == 1; photon cut == 90)\n",
    "\n",
    "# Signals \n",
    "GluGluToHH_df = pd.concat([GluGluToHH_df_2018, GluGluToHH_df_2017, GluGluToHH_df_2016], ignore_index=True)\n",
    "VBFHH_df = pd.concat([VBFHH_df_2018, VBFHH_df_2017, VBFHH_df_2016], ignore_index=True)\n",
    "\n",
    "# Backgrounds\n",
    "VHToGG_df = pd.concat([VHToGG_df_2018, VHToGG_df_2017, VHToGG_df_2016], ignore_index=True)\n",
    "ttHToGG_df = pd.concat([ttHToGG_df_2018, ttHToGG_df_2017, ttHToGG_df_2016], ignore_index=True)\n",
    "VBFHToGG_df = pd.concat([VBFHToGG_df_2018, VBFHToGG_df_2017, VBFHToGG_df_2016], ignore_index=True)\n",
    "GluGluHToGG_df = pd.concat([GluGluHToGG_df_2018, GluGluHToGG_df_2017, GluGluHToGG_df_2016], ignore_index=True)\n",
    "TTJets_df= pd.concat([TTJets_df_2018, TTJets_df_2017, TTJets_df_2016], ignore_index=True)\n",
    "TTGJets_df = pd.concat([TTGJets_df_2018, TTGJets_df_2017, TTGJets_df_2016], ignore_index=True)\n",
    "TTGG_0Jets_df = pd.concat([TTGG_0Jets_df_2018, TTGG_0Jets_df_2017, TTGG_0Jets_df_2016], ignore_index=True)\n",
    "GJet_SmallPt_df = pd.concat([GJet_SmallPt_df_2018, GJet_SmallPt_df_2017, GJet_SmallPt_df_2016], ignore_index=True)\n",
    "GJet_BigPt_df = pd.concat([GJet_BigPt_df_2018, GJet_BigPt_df_2017, GJet_BigPt_df_2016], ignore_index=True)\n",
    "DiPhotonJetsBox_df = pd.concat([DiPhotonJetsBox_df_2018, DiPhotonJetsBox_df_2017, DiPhotonJetsBox_df_2016], ignore_index=True)\n",
    "DiPhotonJetsBox1B_df = pd.concat([DiPhotonJetsBox1B_df_2018, DiPhotonJetsBox1B_df_2017, DiPhotonJetsBox1B_df_2016], ignore_index=True)\n",
    "DiPhotonJetsBox2B_df = pd.concat([DiPhotonJetsBox2B_df_2018, DiPhotonJetsBox2B_df_2017, DiPhotonJetsBox2B_df_2016], ignore_index=True)\n",
    "QCD_Jets_df = pd.concat([QCD_Jets_df_2018, QCD_Jets_df_2017, QCD_Jets_df_2016], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ggHH signal specifically -- pho == 90\n",
    "\n",
    "dfs_combine = [GluGluToHH_df, VBFHH_df,\n",
    "               VHToGG_df, ttHToGG_df, VBFHToGG_df, GluGluHToGG_df, \n",
    "                TTJets_df, TTGJets_df, TTGG_0Jets_df, \n",
    "            GJet_SmallPt_df, GJet_BigPt_df,\n",
    "             DiPhotonJetsBox_df, DiPhotonJetsBox1B_df, DiPhotonJetsBox2B_df, QCD_Jets_df]\n",
    "\n",
    "dfs_ggHH = []\n",
    "\n",
    "for i in range(len(dfs_combine)):\n",
    "    df_ggHH = dfs_combine[i][dfs_combine[i][b'ggHH_recon'] == 1]\n",
    "    dfs_ggHH.append(df_ggHH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b'leading_photon_pt'</th>\n",
       "      <th>b'subleading_photon_pt'</th>\n",
       "      <th>b'diphoton_pt'</th>\n",
       "      <th>b'diphoton_mass'</th>\n",
       "      <th>b'leading_bjet_pt'</th>\n",
       "      <th>b'subleading_bjet_pt'</th>\n",
       "      <th>b'dibjet_pt'</th>\n",
       "      <th>b'dibjet_mass'</th>\n",
       "      <th>b'leading_bjet_pt_corr'</th>\n",
       "      <th>b'subleading_bjet_pt_corr'</th>\n",
       "      <th>...</th>\n",
       "      <th>b'genweight'</th>\n",
       "      <th>b'nbjet'</th>\n",
       "      <th>b'nvbfjet'</th>\n",
       "      <th>b'nphoton'</th>\n",
       "      <th>b'njet'</th>\n",
       "      <th>b'run'</th>\n",
       "      <th>b'lumi'</th>\n",
       "      <th>b'event'</th>\n",
       "      <th>b'label'</th>\n",
       "      <th>b'label_num'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.548317</td>\n",
       "      <td>68.587204</td>\n",
       "      <td>84.036278</td>\n",
       "      <td>124.439453</td>\n",
       "      <td>80.1250</td>\n",
       "      <td>60.7500</td>\n",
       "      <td>88.046196</td>\n",
       "      <td>111.977684</td>\n",
       "      <td>89.827637</td>\n",
       "      <td>63.123047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>112017</td>\n",
       "      <td>GluGluToHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.037231</td>\n",
       "      <td>87.997322</td>\n",
       "      <td>153.144653</td>\n",
       "      <td>124.160385</td>\n",
       "      <td>115.9375</td>\n",
       "      <td>69.3125</td>\n",
       "      <td>160.948395</td>\n",
       "      <td>111.282120</td>\n",
       "      <td>117.749023</td>\n",
       "      <td>75.133667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>112010</td>\n",
       "      <td>GluGluToHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.698898</td>\n",
       "      <td>54.716755</td>\n",
       "      <td>92.352104</td>\n",
       "      <td>124.160637</td>\n",
       "      <td>92.5625</td>\n",
       "      <td>26.7500</td>\n",
       "      <td>112.699577</td>\n",
       "      <td>106.316811</td>\n",
       "      <td>100.517090</td>\n",
       "      <td>32.967285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>112001</td>\n",
       "      <td>GluGluToHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.673645</td>\n",
       "      <td>74.914726</td>\n",
       "      <td>111.698479</td>\n",
       "      <td>120.000145</td>\n",
       "      <td>178.5000</td>\n",
       "      <td>31.0625</td>\n",
       "      <td>172.392776</td>\n",
       "      <td>125.170486</td>\n",
       "      <td>164.816162</td>\n",
       "      <td>27.756042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>112006</td>\n",
       "      <td>GluGluToHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>447.419708</td>\n",
       "      <td>159.403656</td>\n",
       "      <td>594.103027</td>\n",
       "      <td>123.621674</td>\n",
       "      <td>485.0000</td>\n",
       "      <td>46.3750</td>\n",
       "      <td>525.561584</td>\n",
       "      <td>98.438232</td>\n",
       "      <td>465.817871</td>\n",
       "      <td>57.153564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1121</td>\n",
       "      <td>112019</td>\n",
       "      <td>GluGluToHH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b'leading_photon_pt'  b'subleading_photon_pt'  b'diphoton_pt'  \\\n",
       "0             81.548317                68.587204       84.036278   \n",
       "1            109.037231                87.997322      153.144653   \n",
       "2             99.698898                54.716755       92.352104   \n",
       "3             78.673645                74.914726      111.698479   \n",
       "4            447.419708               159.403656      594.103027   \n",
       "\n",
       "   b'diphoton_mass'  b'leading_bjet_pt'  b'subleading_bjet_pt'  b'dibjet_pt'  \\\n",
       "0        124.439453             80.1250                60.7500     88.046196   \n",
       "1        124.160385            115.9375                69.3125    160.948395   \n",
       "2        124.160637             92.5625                26.7500    112.699577   \n",
       "3        120.000145            178.5000                31.0625    172.392776   \n",
       "4        123.621674            485.0000                46.3750    525.561584   \n",
       "\n",
       "   b'dibjet_mass'  b'leading_bjet_pt_corr'  b'subleading_bjet_pt_corr'  ...  \\\n",
       "0      111.977684                89.827637                   63.123047  ...   \n",
       "1      111.282120               117.749023                   75.133667  ...   \n",
       "2      106.316811               100.517090                   32.967285  ...   \n",
       "3      125.170486               164.816162                   27.756042  ...   \n",
       "4       98.438232               465.817871                   57.153564  ...   \n",
       "\n",
       "   b'genweight'  b'nbjet'  b'nvbfjet'  b'nphoton'  b'njet'  b'run'  b'lumi'  \\\n",
       "0     -0.000028         3           0           2        6       1     1121   \n",
       "1      0.000028         2           0           2        5       1     1121   \n",
       "2      0.000028         2           1           2       10       1     1121   \n",
       "3      0.000028         2           0           2       13       1     1121   \n",
       "4      0.000028         2           0           2        8       1     1121   \n",
       "\n",
       "   b'event'    b'label'  b'label_num'  \n",
       "0    112017  GluGluToHH             0  \n",
       "1    112010  GluGluToHH             0  \n",
       "2    112001  GluGluToHH             0  \n",
       "3    112006  GluGluToHH             0  \n",
       "4    112019  GluGluToHH             0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_labels = ['GluGluToHH', 'VBFToHH',\n",
    "            'VHToGG', 'ttHToGG', 'VBFHToGG', 'GluGluHtoGG',\n",
    "            'TTJets', 'TTGJets', 'TTGG_0Jets',\n",
    "            'GJet_SmallPt', 'GJet_BigPt', 'DiPhotonJetsBox', 'DiPhotonJetsBox1B', 'DiPhotonJetsBox2B', 'QCDJets']\n",
    "\n",
    "dfs_ggHH_label = []\n",
    "\n",
    "for i in range(len(mc_labels)):\n",
    "    df = pd.DataFrame()\n",
    "    for column in list(dfs_ggHH[i].columns):\n",
    "        df[column] = dfs_ggHH[i].loc[:, column].values\n",
    "    samp_label = [mc_labels[i]] * len(dfs_ggHH[i].index)\n",
    "    df[b'label'] = samp_label\n",
    "    samp_label_num = [i] * len(dfs_ggHH[i].index)\n",
    "    df[b'label_num'] = samp_label_num\n",
    "    dfs_ggHH_label.append(df)\n",
    "\n",
    "full_df = pd.concat(dfs_ggHH_label, ignore_index=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "training_vars = [b'leading_photon_eta', b'leading_photon_phi', \n",
    "                b'subleading_photon_eta', b'subleading_photon_phi',\n",
    "                 b'leading_bjet_pt_corr', b'leading_bjet_eta', b'leading_bjet_phi',\n",
    "                 b'subleading_bjet_pt_corr', b'subleading_bjet_eta', b'subleading_bjet_phi',\n",
    "                 b'leadingDeepBscore', b'subleadingDeepBscore', b'sumDeepBscore',\n",
    "                 b'leading_pho_pt_over_dimass', b'subleading_pho_pt_over_dimass',\n",
    "                 b'diphoton_pt_over_diphoton_mass', b'dibjet_pt_over_dibjet_mass_corr',\n",
    "                 b'rec_pho_bjet_min_dR', b'all_pho_bjet_min_dR', b'dphi_met_leading_bjet', b'dphi_met_subleading_bjet',\n",
    "                 b'MET_pt', b'MET_phi', b'MET_sumEt',\n",
    "                 b'nbjet', b'nphoton', b'njet'\n",
    "                ]\n",
    "\n",
    "aug_vars = [b'dibjet_mass', b'diphoton_mass', b'event']\n",
    "\n",
    "w_var = [b'genweight']\n",
    "\n",
    "# select df columns\n",
    "x_df = full_df[training_vars]\n",
    "x_full_df = full_df[training_vars + aug_vars + w_var]\n",
    "y_df = full_df[b'label_num']\n",
    "X = x_df.values\n",
    "Y = y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test; following: https://www.kaggle.com/hungdo1291/keras-dnn-multi-class\n",
    "random_seed=2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=random_seed)\n",
    "Y_train_dummy = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # following: https://www.kaggle.com/hungdo1291/keras-dnn-multi-class\n",
    "\n",
    "# def precision(y_true, y_pred): \n",
    "#     \"\"\"Precision metric. Only computes a batch-wise average of precision.  \n",
    "# -    Computes the precision, a metric for multi-label classification of \n",
    "# -    how many selected items are relevant. \n",
    "# -    \"\"\" \n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) \n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) \n",
    "#     precision = true_positives / (predicted_positives + K.epsilon()) \n",
    "#     return precision \n",
    "\n",
    "\n",
    "# def recall(y_true, y_pred): \n",
    "#     \"\"\"Recall metric. \n",
    "# -    Only computes a batch-wise average of recall. \n",
    "# -    Computes the recall, a metric for multi-label classification of \n",
    "# -    how many relevant items are selected. \n",
    "# -    \"\"\" \n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) \n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) \n",
    "#     recall = true_positives / (possible_positives + K.epsilon()) \n",
    "#     return recall \n",
    "\n",
    "\n",
    "# def fbeta_score(y_true, y_pred, beta=1): \n",
    "\n",
    "#     \"\"\"Computes the F score.  \n",
    "# -    The F score is the weighted harmonic mean of precision and recall. \n",
    "# -    Here it is only computed as a batch-wise average, not globally. \n",
    "# -    This is useful for multi-label classification, where input samples can be \n",
    "# -    classified as sets of labels. By only using accuracy (precision) a model \n",
    "# -    would achieve a perfect score by simply assigning every class to every \n",
    "# -    input. In order to avoid this, a metric should penalize incorrect class \n",
    "# -    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0) \n",
    "# -    computes this, as a weighted mean of the proportion of correct class \n",
    "# -    assignments vs. the proportion of incorrect class assignments.  \n",
    "# -    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning \n",
    "# -    correct classes becomes more important, and with beta > 1 the metric is \n",
    "# -    instead weighted towards penalizing incorrect class assignments. \n",
    "# -    \"\"\" \n",
    "#     if beta < 0: \n",
    "#         raise ValueError('The lowest choosable beta is zero (only precision).') \n",
    "\n",
    "#     # If there are no true positives, fix the F score at 0 like sklearn. \n",
    "#     if K.sum(K.round(K.clip(y_true, 0, 1))) == 0: \n",
    "\n",
    "#         return 0 \n",
    "#     p = precision(y_true, y_pred) \n",
    "#     r = recall(y_true, y_pred) \n",
    "#     bb = beta ** 2 \n",
    "#     fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon()) \n",
    "#     return fbeta_score \n",
    "\n",
    "# def fmeasure(y_true, y_pred): \n",
    "#     \"\"\"Computes the f-measure, the harmonic mean of precision and recall. \n",
    "#     Here it is only computed as a batch-wise average, not globally. \n",
    "#     \"\"\" \n",
    "#     return fbeta_score(y_true, y_pred, beta=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_DNN(n_hidden = 1, first_neuron = 100, n_neurons = 64, dropout_rate = 0.4, activation_func = 'sigmoid', lr= 0.00002):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_neuron, input_dim=len(training_vars), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation = activation_func))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(15, activation = 'softmax'))\n",
    "    opt = Adam(learning_rate = lr)\n",
    "    model.compile(loss=CategoricalCrossentropy(), optimizer=opt, metrics=[CategoricalAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.7864 - categorical_accuracy: 0.5749 - val_loss: 1.6291 - val_categorical_accuracy: 0.5966\n",
      "Epoch 2/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.6649 - categorical_accuracy: 0.5972 - val_loss: 1.6123 - val_categorical_accuracy: 0.5966\n",
      "Epoch 3/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.6359 - categorical_accuracy: 0.5982 - val_loss: 1.5924 - val_categorical_accuracy: 0.6001\n",
      "Epoch 4/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.6112 - categorical_accuracy: 0.5992 - val_loss: 1.5519 - val_categorical_accuracy: 0.6001\n",
      "Epoch 5/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.5757 - categorical_accuracy: 0.6000 - val_loss: 1.5158 - val_categorical_accuracy: 0.6003\n",
      "Epoch 6/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.5400 - categorical_accuracy: 0.6040 - val_loss: 1.4966 - val_categorical_accuracy: 0.6151\n",
      "Epoch 7/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.5153 - categorical_accuracy: 0.6096 - val_loss: 1.4746 - val_categorical_accuracy: 0.6180\n",
      "Epoch 8/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.4947 - categorical_accuracy: 0.6143 - val_loss: 1.4562 - val_categorical_accuracy: 0.6198\n",
      "Epoch 9/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.4709 - categorical_accuracy: 0.6178 - val_loss: 1.4238 - val_categorical_accuracy: 0.6212\n",
      "Epoch 10/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.4279 - categorical_accuracy: 0.6206 - val_loss: 1.3407 - val_categorical_accuracy: 0.6260\n",
      "Epoch 11/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.3670 - categorical_accuracy: 0.6270 - val_loss: 1.2809 - val_categorical_accuracy: 0.6403\n",
      "Epoch 12/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.3256 - categorical_accuracy: 0.6348 - val_loss: 1.2578 - val_categorical_accuracy: 0.6499\n",
      "Epoch 13/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.3020 - categorical_accuracy: 0.6399 - val_loss: 1.2479 - val_categorical_accuracy: 0.6527\n",
      "Epoch 14/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2873 - categorical_accuracy: 0.6435 - val_loss: 1.2390 - val_categorical_accuracy: 0.6540\n",
      "Epoch 15/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2767 - categorical_accuracy: 0.6461 - val_loss: 1.2332 - val_categorical_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2686 - categorical_accuracy: 0.6479 - val_loss: 1.2279 - val_categorical_accuracy: 0.6559\n",
      "Epoch 17/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2621 - categorical_accuracy: 0.6494 - val_loss: 1.2227 - val_categorical_accuracy: 0.6573\n",
      "Epoch 18/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2570 - categorical_accuracy: 0.6504 - val_loss: 1.2173 - val_categorical_accuracy: 0.6582\n",
      "Epoch 19/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2523 - categorical_accuracy: 0.6515 - val_loss: 1.2125 - val_categorical_accuracy: 0.6586\n",
      "Epoch 20/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2484 - categorical_accuracy: 0.6520 - val_loss: 1.2082 - val_categorical_accuracy: 0.6595\n",
      "Epoch 21/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2449 - categorical_accuracy: 0.6525 - val_loss: 1.2041 - val_categorical_accuracy: 0.6595\n",
      "Epoch 22/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2420 - categorical_accuracy: 0.6532 - val_loss: 1.2010 - val_categorical_accuracy: 0.6605\n",
      "Epoch 23/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2392 - categorical_accuracy: 0.6539 - val_loss: 1.1992 - val_categorical_accuracy: 0.6603\n",
      "Epoch 24/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2364 - categorical_accuracy: 0.6542 - val_loss: 1.1964 - val_categorical_accuracy: 0.6610\n",
      "Epoch 25/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.2344 - categorical_accuracy: 0.6547 - val_loss: 1.1929 - val_categorical_accuracy: 0.6611\n",
      "Epoch 26/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2318 - categorical_accuracy: 0.6551 - val_loss: 1.1917 - val_categorical_accuracy: 0.6615\n",
      "Epoch 27/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.2293 - categorical_accuracy: 0.6555 - val_loss: 1.1901 - val_categorical_accuracy: 0.6616\n",
      "Epoch 28/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2272 - categorical_accuracy: 0.6558 - val_loss: 1.1861 - val_categorical_accuracy: 0.6620\n",
      "Epoch 29/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2246 - categorical_accuracy: 0.6563 - val_loss: 1.1846 - val_categorical_accuracy: 0.6624\n",
      "Epoch 30/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2230 - categorical_accuracy: 0.6568 - val_loss: 1.1841 - val_categorical_accuracy: 0.6625\n",
      "Epoch 31/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2214 - categorical_accuracy: 0.6570 - val_loss: 1.1827 - val_categorical_accuracy: 0.6629\n",
      "Epoch 32/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.2197 - categorical_accuracy: 0.6573 - val_loss: 1.1812 - val_categorical_accuracy: 0.6629\n",
      "Epoch 33/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2185 - categorical_accuracy: 0.6577 - val_loss: 1.1808 - val_categorical_accuracy: 0.6632\n",
      "Epoch 34/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.2174 - categorical_accuracy: 0.6577 - val_loss: 1.1781 - val_categorical_accuracy: 0.6636\n",
      "Epoch 35/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2161 - categorical_accuracy: 0.6580 - val_loss: 1.1775 - val_categorical_accuracy: 0.6639\n",
      "Epoch 36/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2151 - categorical_accuracy: 0.6581 - val_loss: 1.1766 - val_categorical_accuracy: 0.6639\n",
      "Epoch 37/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2137 - categorical_accuracy: 0.6585 - val_loss: 1.1750 - val_categorical_accuracy: 0.6640\n",
      "Epoch 38/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2126 - categorical_accuracy: 0.6587 - val_loss: 1.1742 - val_categorical_accuracy: 0.6641\n",
      "Epoch 39/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2118 - categorical_accuracy: 0.6589 - val_loss: 1.1730 - val_categorical_accuracy: 0.6649\n",
      "Epoch 40/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2105 - categorical_accuracy: 0.6589 - val_loss: 1.1734 - val_categorical_accuracy: 0.6645\n",
      "Epoch 41/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2096 - categorical_accuracy: 0.6591 - val_loss: 1.1721 - val_categorical_accuracy: 0.6651\n",
      "Epoch 42/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2087 - categorical_accuracy: 0.6591 - val_loss: 1.1710 - val_categorical_accuracy: 0.6651\n",
      "Epoch 43/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2078 - categorical_accuracy: 0.6594 - val_loss: 1.1702 - val_categorical_accuracy: 0.6652\n",
      "Epoch 44/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2064 - categorical_accuracy: 0.6597 - val_loss: 1.1682 - val_categorical_accuracy: 0.6654\n",
      "Epoch 45/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2057 - categorical_accuracy: 0.6597 - val_loss: 1.1681 - val_categorical_accuracy: 0.6655\n",
      "Epoch 46/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2050 - categorical_accuracy: 0.6600 - val_loss: 1.1699 - val_categorical_accuracy: 0.6657\n",
      "Epoch 47/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2038 - categorical_accuracy: 0.6601 - val_loss: 1.1652 - val_categorical_accuracy: 0.6662\n",
      "Epoch 48/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2029 - categorical_accuracy: 0.6603 - val_loss: 1.1656 - val_categorical_accuracy: 0.6660\n",
      "Epoch 49/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2020 - categorical_accuracy: 0.6605 - val_loss: 1.1647 - val_categorical_accuracy: 0.6664\n",
      "Epoch 50/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.2015 - categorical_accuracy: 0.6606 - val_loss: 1.1623 - val_categorical_accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2005 - categorical_accuracy: 0.6608 - val_loss: 1.1617 - val_categorical_accuracy: 0.6668\n",
      "Epoch 52/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.2002 - categorical_accuracy: 0.6608 - val_loss: 1.1614 - val_categorical_accuracy: 0.6666\n",
      "Epoch 53/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1991 - categorical_accuracy: 0.6611 - val_loss: 1.1611 - val_categorical_accuracy: 0.6669\n",
      "Epoch 54/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1983 - categorical_accuracy: 0.6615 - val_loss: 1.1601 - val_categorical_accuracy: 0.6674\n",
      "Epoch 55/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1977 - categorical_accuracy: 0.6611 - val_loss: 1.1592 - val_categorical_accuracy: 0.6672\n",
      "Epoch 56/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1973 - categorical_accuracy: 0.6617 - val_loss: 1.1579 - val_categorical_accuracy: 0.6675\n",
      "Epoch 57/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1965 - categorical_accuracy: 0.6616 - val_loss: 1.1591 - val_categorical_accuracy: 0.6673\n",
      "Epoch 58/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1959 - categorical_accuracy: 0.6619 - val_loss: 1.1568 - val_categorical_accuracy: 0.6676\n",
      "Epoch 59/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1953 - categorical_accuracy: 0.6618 - val_loss: 1.1572 - val_categorical_accuracy: 0.6679\n",
      "Epoch 60/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1949 - categorical_accuracy: 0.6621 - val_loss: 1.1567 - val_categorical_accuracy: 0.6677\n",
      "Epoch 61/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1944 - categorical_accuracy: 0.6622 - val_loss: 1.1563 - val_categorical_accuracy: 0.6682\n",
      "Epoch 62/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1944 - categorical_accuracy: 0.6620 - val_loss: 1.1562 - val_categorical_accuracy: 0.6678\n",
      "Epoch 63/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1936 - categorical_accuracy: 0.6625 - val_loss: 1.1556 - val_categorical_accuracy: 0.6685\n",
      "Epoch 64/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1935 - categorical_accuracy: 0.6623 - val_loss: 1.1544 - val_categorical_accuracy: 0.6687\n",
      "Epoch 65/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1927 - categorical_accuracy: 0.6625 - val_loss: 1.1547 - val_categorical_accuracy: 0.6684\n",
      "Epoch 66/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1923 - categorical_accuracy: 0.6626 - val_loss: 1.1529 - val_categorical_accuracy: 0.6689\n",
      "Epoch 67/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1917 - categorical_accuracy: 0.6628 - val_loss: 1.1536 - val_categorical_accuracy: 0.6693\n",
      "Epoch 68/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1917 - categorical_accuracy: 0.6628 - val_loss: 1.1526 - val_categorical_accuracy: 0.6688\n",
      "Epoch 69/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1910 - categorical_accuracy: 0.6630 - val_loss: 1.1520 - val_categorical_accuracy: 0.6689\n",
      "Epoch 70/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1907 - categorical_accuracy: 0.6631 - val_loss: 1.1530 - val_categorical_accuracy: 0.6685\n",
      "Epoch 71/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1902 - categorical_accuracy: 0.6632 - val_loss: 1.1522 - val_categorical_accuracy: 0.6690\n",
      "Epoch 72/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1902 - categorical_accuracy: 0.6633 - val_loss: 1.1516 - val_categorical_accuracy: 0.6694\n",
      "Epoch 73/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1895 - categorical_accuracy: 0.6631 - val_loss: 1.1518 - val_categorical_accuracy: 0.6691\n",
      "Epoch 74/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1893 - categorical_accuracy: 0.6633 - val_loss: 1.1527 - val_categorical_accuracy: 0.6695\n",
      "Epoch 75/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1892 - categorical_accuracy: 0.6637 - val_loss: 1.1512 - val_categorical_accuracy: 0.6688\n",
      "Epoch 76/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1885 - categorical_accuracy: 0.6637 - val_loss: 1.1496 - val_categorical_accuracy: 0.6698\n",
      "Epoch 77/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1882 - categorical_accuracy: 0.6637 - val_loss: 1.1490 - val_categorical_accuracy: 0.6698\n",
      "Epoch 78/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1878 - categorical_accuracy: 0.6636 - val_loss: 1.1501 - val_categorical_accuracy: 0.6693\n",
      "Epoch 79/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1876 - categorical_accuracy: 0.6638 - val_loss: 1.1498 - val_categorical_accuracy: 0.6702\n",
      "Epoch 80/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1873 - categorical_accuracy: 0.6639 - val_loss: 1.1488 - val_categorical_accuracy: 0.6705\n",
      "Epoch 81/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1867 - categorical_accuracy: 0.6640 - val_loss: 1.1483 - val_categorical_accuracy: 0.6700\n",
      "Epoch 82/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1859 - categorical_accuracy: 0.6641 - val_loss: 1.1492 - val_categorical_accuracy: 0.6701\n",
      "Epoch 83/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1861 - categorical_accuracy: 0.6643 - val_loss: 1.1488 - val_categorical_accuracy: 0.6697\n",
      "Epoch 84/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1857 - categorical_accuracy: 0.6642 - val_loss: 1.1478 - val_categorical_accuracy: 0.6702\n",
      "Epoch 85/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1863 - categorical_accuracy: 0.6639 - val_loss: 1.1472 - val_categorical_accuracy: 0.6705\n",
      "Epoch 86/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1855 - categorical_accuracy: 0.6642 - val_loss: 1.1474 - val_categorical_accuracy: 0.6705\n",
      "Epoch 87/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1855 - categorical_accuracy: 0.6642 - val_loss: 1.1491 - val_categorical_accuracy: 0.6708\n",
      "Epoch 88/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1850 - categorical_accuracy: 0.6643 - val_loss: 1.1470 - val_categorical_accuracy: 0.6705\n",
      "Epoch 89/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1850 - categorical_accuracy: 0.6643 - val_loss: 1.1465 - val_categorical_accuracy: 0.6704\n",
      "Epoch 90/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1847 - categorical_accuracy: 0.6643 - val_loss: 1.1454 - val_categorical_accuracy: 0.6703\n",
      "Epoch 91/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1845 - categorical_accuracy: 0.6646 - val_loss: 1.1460 - val_categorical_accuracy: 0.6706\n",
      "Epoch 92/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1840 - categorical_accuracy: 0.6645 - val_loss: 1.1481 - val_categorical_accuracy: 0.6703\n",
      "Epoch 93/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1840 - categorical_accuracy: 0.6647 - val_loss: 1.1452 - val_categorical_accuracy: 0.6710\n",
      "Epoch 94/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1838 - categorical_accuracy: 0.6647 - val_loss: 1.1448 - val_categorical_accuracy: 0.6710\n",
      "Epoch 95/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1835 - categorical_accuracy: 0.6648 - val_loss: 1.1448 - val_categorical_accuracy: 0.6712\n",
      "Epoch 96/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1838 - categorical_accuracy: 0.6648 - val_loss: 1.1443 - val_categorical_accuracy: 0.6710\n",
      "Epoch 97/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1835 - categorical_accuracy: 0.6649 - val_loss: 1.1448 - val_categorical_accuracy: 0.6711\n",
      "Epoch 98/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1831 - categorical_accuracy: 0.6650 - val_loss: 1.1448 - val_categorical_accuracy: 0.6713\n",
      "Epoch 99/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1829 - categorical_accuracy: 0.6651 - val_loss: 1.1443 - val_categorical_accuracy: 0.6711\n",
      "Epoch 100/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1826 - categorical_accuracy: 0.6652 - val_loss: 1.1434 - val_categorical_accuracy: 0.6718\n",
      "Epoch 101/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1824 - categorical_accuracy: 0.6651 - val_loss: 1.1439 - val_categorical_accuracy: 0.6718\n",
      "Epoch 102/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1821 - categorical_accuracy: 0.6654 - val_loss: 1.1438 - val_categorical_accuracy: 0.6715\n",
      "Epoch 103/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1821 - categorical_accuracy: 0.6652 - val_loss: 1.1428 - val_categorical_accuracy: 0.6714\n",
      "Epoch 104/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1816 - categorical_accuracy: 0.6654 - val_loss: 1.1441 - val_categorical_accuracy: 0.6717\n",
      "Epoch 105/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1815 - categorical_accuracy: 0.6653 - val_loss: 1.1435 - val_categorical_accuracy: 0.6720\n",
      "Epoch 106/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1812 - categorical_accuracy: 0.6655 - val_loss: 1.1434 - val_categorical_accuracy: 0.6727\n",
      "Epoch 107/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1805 - categorical_accuracy: 0.6658 - val_loss: 1.1421 - val_categorical_accuracy: 0.6720\n",
      "Epoch 108/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1803 - categorical_accuracy: 0.6659 - val_loss: 1.1408 - val_categorical_accuracy: 0.6726\n",
      "Epoch 109/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1803 - categorical_accuracy: 0.6659 - val_loss: 1.1405 - val_categorical_accuracy: 0.6723\n",
      "Epoch 110/200\n",
      "33026/33026 [==============================] - 55s 2ms/step - loss: 1.1801 - categorical_accuracy: 0.6660 - val_loss: 1.1401 - val_categorical_accuracy: 0.6726\n",
      "Epoch 111/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1794 - categorical_accuracy: 0.6662 - val_loss: 1.1396 - val_categorical_accuracy: 0.6730\n",
      "Epoch 112/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1796 - categorical_accuracy: 0.6661 - val_loss: 1.1405 - val_categorical_accuracy: 0.6720\n",
      "Epoch 113/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1791 - categorical_accuracy: 0.6662 - val_loss: 1.1388 - val_categorical_accuracy: 0.6732\n",
      "Epoch 114/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1790 - categorical_accuracy: 0.6663 - val_loss: 1.1399 - val_categorical_accuracy: 0.6728\n",
      "Epoch 115/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1791 - categorical_accuracy: 0.6663 - val_loss: 1.1403 - val_categorical_accuracy: 0.6728\n",
      "Epoch 116/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1785 - categorical_accuracy: 0.6665 - val_loss: 1.1374 - val_categorical_accuracy: 0.6736\n",
      "Epoch 117/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1782 - categorical_accuracy: 0.6667 - val_loss: 1.1364 - val_categorical_accuracy: 0.6736\n",
      "Epoch 118/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1783 - categorical_accuracy: 0.6667 - val_loss: 1.1378 - val_categorical_accuracy: 0.6733\n",
      "Epoch 119/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1777 - categorical_accuracy: 0.6666 - val_loss: 1.1388 - val_categorical_accuracy: 0.6729\n",
      "Epoch 120/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1777 - categorical_accuracy: 0.6667 - val_loss: 1.1360 - val_categorical_accuracy: 0.6740\n",
      "Epoch 121/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1777 - categorical_accuracy: 0.6667 - val_loss: 1.1388 - val_categorical_accuracy: 0.6741\n",
      "Epoch 122/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1775 - categorical_accuracy: 0.6667 - val_loss: 1.1375 - val_categorical_accuracy: 0.6734\n",
      "Epoch 123/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1772 - categorical_accuracy: 0.6667 - val_loss: 1.1368 - val_categorical_accuracy: 0.6742\n",
      "Epoch 124/200\n",
      "33026/33026 [==============================] - 57s 2ms/step - loss: 1.1773 - categorical_accuracy: 0.6669 - val_loss: 1.1366 - val_categorical_accuracy: 0.6740\n",
      "Epoch 125/200\n",
      "33026/33026 [==============================] - 56s 2ms/step - loss: 1.1765 - categorical_accuracy: 0.6670 - val_loss: 1.1366 - val_categorical_accuracy: 0.6737\n",
      "Epoch 00125: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = multi_DNN()\n",
    "history = model.fit(X_train, Y_train_dummy, epochs=200,batch_size=64, validation_split = 0.2, \n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20641/20641 [==============================] - 24s 1ms/step - loss: 1.1360 - categorical_accuracy: 0.6739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1360400915145874, 0.6738505363464355]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_dummy = np_utils.to_categorical(Y_val)\n",
    "model.evaluate(X_val, Y_val_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.0512249e-01 6.7714551e-03 3.1499397e-03 5.6102205e-02 4.2781346e-03\n",
      " 5.7956960e-02 2.2415115e-04 9.1528433e-05 7.5978220e-05 2.1229168e-04\n",
      " 1.6477642e-03 3.1100949e-02 1.0379279e-03 3.2087151e-02 1.4109601e-04]\n"
     ]
    }
   ],
   "source": [
    "print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame()\n",
    "output = model.predict(X_val)\n",
    "#compare['output'] = output\n",
    "predict_lab = []\n",
    "predict_name = []\n",
    "actual_name = []\n",
    "for i in range(output.shape[0]):\n",
    "    label = np.argmax(output[i])\n",
    "    predict_lab.append(label)\n",
    "    predict_name.append(mc_labels[label])\n",
    "    actual_name.append(mc_labels[Y_val[i]])\n",
    "compare['predicted_label'] = predict_lab\n",
    "compare['actual_label'] = Y_val\n",
    "compare['predicted_name'] = predict_name\n",
    "compare['actual_name'] = actual_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04070036789753372\n",
      "0.0347473921666591\n",
      "0.034876080604381465\n",
      "115095\n"
     ]
    }
   ],
   "source": [
    "print(predict_lab.count(0) / len(predict_lab))\n",
    "print(np.count_nonzero(Y_val == 0) / Y_val.shape[0])\n",
    "print(np.count_nonzero(Y_train == 0) / Y_train.shape[0])\n",
    "print(np.count_nonzero(Y_val == 0) + np.count_nonzero(Y_train == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_name</th>\n",
       "      <th>actual_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406354</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121627</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440676</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>VBFHToGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137920</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370265</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584619</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>VHToGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411196</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228474</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625516</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>GJet_BigPt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114924</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242572</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129518</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534170</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417586</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652512</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326806</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>ttHToGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625803</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>TTJets</td>\n",
       "      <td>TTJets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168118</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox1B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600985</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264908</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>TTJets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587426</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598651</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269800</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597801</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208251</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235937</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ttHToGG</td>\n",
       "      <td>ttHToGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425623</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325875</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>TTGJets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321007</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116304</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox1B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385164</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195814</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37272</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322946</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>GluGluHtoGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254669</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538972</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208041</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37454</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507436</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35167</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503156</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38843</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>GluGluHtoGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574347</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>TTJets</td>\n",
       "      <td>TTJets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307769</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>VBFHToGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148769</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642325</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>GJet_BigPt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163124</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495121</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493008</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353968</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "      <td>DiPhotonJetsBox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predicted_label  actual_label   predicted_name        actual_name\n",
       "406354               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "121627               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "440676               11             4  DiPhotonJetsBox           VBFHToGG\n",
       "137920               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "370265               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "584619               11             2  DiPhotonJetsBox             VHToGG\n",
       "411196               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "228474               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "625516               11            10  DiPhotonJetsBox         GJet_BigPt\n",
       "114924               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "242572               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "129518               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "534170               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "417586               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "652512               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "326806               11             3  DiPhotonJetsBox            ttHToGG\n",
       "625803                6             6           TTJets             TTJets\n",
       "168118               11            12  DiPhotonJetsBox  DiPhotonJetsBox1B\n",
       "600985               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "264908               11             6  DiPhotonJetsBox             TTJets\n",
       "587426               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "598651               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "269800               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "597801               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "208251               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "235937                3             3          ttHToGG            ttHToGG\n",
       "425623               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "325875               11             7  DiPhotonJetsBox            TTGJets\n",
       "321007               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "116304               11            12  DiPhotonJetsBox  DiPhotonJetsBox1B\n",
       "385164               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "195814               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "37272                11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "322946               11             5  DiPhotonJetsBox        GluGluHtoGG\n",
       "254669               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "538972               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "208041               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "37454                11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "507436               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "35167                11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "503156               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "38843                11             5  DiPhotonJetsBox        GluGluHtoGG\n",
       "574347                6             6           TTJets             TTJets\n",
       "307769               11             4  DiPhotonJetsBox           VBFHToGG\n",
       "148769               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "642325               11            10  DiPhotonJetsBox         GJet_BigPt\n",
       "163124               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "495121               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "493008               11            11  DiPhotonJetsBox    DiPhotonJetsBox\n",
       "353968               11            11  DiPhotonJetsBox    DiPhotonJetsBox"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "\n",
    "n_classes = Y.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score.ravel())\n",
    "\n",
    "\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2191610e-01 1.0798335e-01 6.5229744e-02 ... 4.2139739e-02\n",
      "  1.2250453e-02 4.8553377e-02]\n",
      " [8.0013245e-01 1.0684222e-02 4.4399798e-03 ... 2.8002560e-03\n",
      "  4.7476411e-02 6.4437091e-03]\n",
      " [7.5319552e-01 4.7617555e-03 1.9856989e-03 ... 1.5153289e-03\n",
      "  7.4679196e-02 3.9824843e-03]\n",
      " ...\n",
      " [8.0017841e-01 1.2610495e-02 5.7884753e-03 ... 8.4994137e-03\n",
      "  1.2677610e-02 5.8728456e-04]\n",
      " [7.8339016e-01 6.5042377e-03 2.9864609e-03 ... 1.7688870e-03\n",
      "  4.5274645e-02 2.0082593e-03]\n",
      " [7.7708590e-01 4.1216016e-03 1.5176535e-03 ... 1.3048649e-03\n",
      "  8.0464065e-02 4.5357943e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 77.94%\n"
     ]
    }
   ],
   "source": [
    "y_train_tmp = model.predict(X_train)\n",
    "predictions_train_tmp = [round(value[0]) for value in y_train_tmp]\n",
    "train_accuracy = accuracy_score(Y_train_dummy[:, 0], predictions_train_tmp)\n",
    "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
    "\n",
    "y_pred_tmp = model.predict(X_val)\n",
    "predictions_tmp = [round(value[0]) for value in y_pred_tmp]\n",
    "accuracy = accuracy_score(Y_val, predictions_tmp)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_DNN(n_hidden = 1, first_neuron = 100, n_neurons = 64, dropout_rate = 0.4, activation_func = 'sigmoid', lr= 0.00002):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_neuron, input_dim=len(training_vars), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation = activation_func))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    opt = Adam(learning_rate = lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = KerasClassifier(build_fn=multi_DNN, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space  = [Integer(1, 5, name='n_hidden'),\n",
    "          Integer(10, 128, name='first_neuron'),\n",
    "          Integer(10, 128, name = 'n_neurons'),\n",
    "          Real(0.01,0.9,name='dropout_rate'),\n",
    "          Categorical(['relu', 'sigmoid', 'softmax']),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate')\n",
    "         ]\n",
    "\n",
    "def multi_DNN(n_hidden = 1, first_neuron = 100, n_neurons = 64, dropout_rate = 0.4, activation_func = 'sigmoid', lr= 0.00002):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_neuron, input_dim=len(training_vars), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation = activation_func))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    opt = Adam(learning_rate = lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# @use_named_args(space)\n",
    "# def objective(**X):\n",
    "#     print(\"New configuration: {}\".format(X))\n",
    "#     model_tmp = multi_DNN(X['n_hidden'], X['first_neuron'], X['n_neurons'], X['dropout_rate'], X['activation_func'], X['lr'])\n",
    "#     print (model_tmp)\n",
    "#     estimator_tmp = KerasClassifier(build_fn=model_temp, epochs=200, batch_size=5, verbose=0)\n",
    "#     kfold = KFold(n_splits=10, shuffle=True)\n",
    "#     results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "#     model_tmp.fit(x_train, y_train, epochs = 50, verbose = 1, validation_split = 0.2,  callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min'),\n",
    "#                             ModelCheckpoint(filepath='Models/optimize_trial/'+names[i]+'_opt_mass_model.h5', verbose=0)])\n",
    "    \n",
    "#     y_train_tmp = model_tmp.predict(x_train)\n",
    "#     predictions_train_tmp = [round(value[0]) for value in y_train_tmp]\n",
    "#     train_accuracy = accuracy_score(y_train, predictions_train_tmp)\n",
    "#     print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    \n",
    "#     y_pred_tmp = model_tmp.predict(x_test)\n",
    "#     predictions_tmp = [round(value[0]) for value in y_pred_tmp]\n",
    "#     accuracy = accuracy_score(y_test, predictions_tmp)\n",
    "#     print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    \n",
    "#     return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=multi_DNN, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
